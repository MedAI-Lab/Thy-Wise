{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary dependency libraries\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model performance test functions\n",
    "def performance_xgboost(xtrainup,ytrainup,xtrain,ytrain):\n",
    "    clf.fit(xtrainup, ytrainup)\n",
    "    # AUC\n",
    "    auc_scores = roc_auc_score(ytrain, clf.predict_proba(xtrain)[:,1])\n",
    "    print('auc = ', \"%.3f\"%auc_scores)\n",
    "    # accuracy\n",
    "    from sklearn.metrics import accuracy_score\n",
    "    accuracy = accuracy_score(ytrain, clf.predict(xtrain))*100\n",
    "    print('accuracy = ', \"%.1f\"%accuracy)\n",
    "    print('------------------------')\n",
    "    # 混淆矩阵\n",
    "    import sklearn.metrics as sm\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    matrix = confusion_matrix(ytrain, clf.predict(xtrain), labels=None, sample_weight=None)\n",
    "    print('混淆矩阵为：')\n",
    "    print(matrix)\n",
    "    (tn,fp,fn,tp) = matrix.ravel()\n",
    "    print('tn=',tn)\n",
    "    print('fp=',fp)\n",
    "    print('fn=',fn)\n",
    "    print('tp=',tp)\n",
    "    print('------------------------')\n",
    "    sensitivity = (tp/(tp+fn))*100\n",
    "    specificity = (tn/(fp+tn))*100\n",
    "    PPV=tp/(tp+fp)*100\n",
    "    NPV=tn/(fn+tn)*100\n",
    "    print(f'PPV = {\"%.1f\"%PPV}\\n({tp}/{(tp+fp)})')\n",
    "    print(f'NPV = {\"%.1f\"%NPV}\\n({tn}/{(fn+tn)})')\n",
    "    print(f'sensitivity = {\"%.1f\"%sensitivity}\\n({tp}/{(tp+fn)})')\n",
    "    print(f'specificity = {\"%.1f\"%specificity}\\n({tn}/{(fp+tn)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jinzh\\anaconda3\\lib\\site-packages\\imblearn\\utils\\_validation.py:299: UserWarning: After over-sampling, the number of samples (2200) in class 1 will be larger than the number of samples in the majority class (class #0 -> 1582)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Reading data\n",
    "train = pd.read_csv('F:/Onedrive/JIMMY/Python/Notebook/data_set/inuse/train.csv',encoding='gbk')\n",
    "test = pd.read_csv('F:/Onedrive/JIMMY/Python/Notebook/data_set/inuse/test.csv',encoding='gbk')\n",
    "validation = pd.read_csv('F:/Onedrive/JIMMY/Python/Notebook/data_set/inuse/validation_new04.csv',encoding='gbk')\n",
    "\n",
    "xtrain = train.iloc[:,1:14]\n",
    "xtest = test.iloc[:,1:14]\n",
    "xv = validation.iloc[:,1:14]\n",
    "ytrain = train.iloc[:,-1]\n",
    "ytest = test.iloc[:,-1]\n",
    "yv = validation.iloc[:,-1]\n",
    "\n",
    "# Up-sampling processing\n",
    "sm = SMOTE(sampling_strategy={1: 2200},random_state=100) \n",
    "xtrainup,ytrainup = sm.fit_resample(xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:34:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.9, gamma=1, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.01, max_delta_step=0, max_depth=3,\n",
       "              min_child_weight=4, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=250, n_jobs=-1, nthread=4, num_parallel_tree=1,\n",
       "              random_state=27, reg_alpha=0.17, reg_lambda=1,\n",
       "              scale_pos_weight=0.9, seed=27, subsample=0.8, tree_method='auto',\n",
       "              use_label_encoder=False, validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Instantiation\n",
    "clf = XGBClassifier(use_label_encoder=False\n",
    "                   ,learning_rate =0.01  \n",
    "                   ,n_estimators=250\n",
    "                   ,max_depth=3\n",
    "                   ,min_child_weight=4\n",
    "                   ,gamma=1\n",
    "                   ,subsample=0.8\n",
    "                   ,colsample_bytree=0.9\n",
    "                   ,objective= 'binary:logistic'\n",
    "                   ,scale_pos_weight=0.9\n",
    "                   ,nthread=4\n",
    "                   ,reg_alpha=0.17\n",
    "                   ,tree_method='auto'\n",
    "                   ,seed=27\n",
    "                   ,n_jobs=-1) \n",
    "clf.fit(xtrainup, ytrainup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:34:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "auc =  0.935\n",
      "accuracy =  83.3\n",
      "------------------------\n",
      "混淆矩阵为：\n",
      "[[1261  321]\n",
      " [  42  544]]\n",
      "tn= 1261\n",
      "fp= 321\n",
      "fn= 42\n",
      "tp= 544\n",
      "------------------------\n",
      "PPV = 62.9\n",
      "(544/865)\n",
      "NPV = 96.8\n",
      "(1261/1303)\n",
      "sensitivity = 92.8\n",
      "(544/586)\n",
      "specificity = 79.7\n",
      "(1261/1582)\n"
     ]
    }
   ],
   "source": [
    "# Testing the model on the training set\n",
    "performance_xgboost(xtrainup,ytrainup,xtrain,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:34:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "auc =  0.908\n",
      "accuracy =  81.8\n",
      "------------------------\n",
      "混淆矩阵为：\n",
      "[[522 144]\n",
      " [ 25 239]]\n",
      "tn= 522\n",
      "fp= 144\n",
      "fn= 25\n",
      "tp= 239\n",
      "------------------------\n",
      "PPV = 62.4\n",
      "(239/383)\n",
      "NPV = 95.4\n",
      "(522/547)\n",
      "sensitivity = 90.5\n",
      "(239/264)\n",
      "specificity = 78.4\n",
      "(522/666)\n"
     ]
    }
   ],
   "source": [
    "# Testing the model on the internal validation set\n",
    "performance_xgboost(xtrainup,ytrainup,xtest,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:34:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "auc =  0.863\n",
      "accuracy =  75.8\n",
      "------------------------\n",
      "混淆矩阵为：\n",
      "[[466 166]\n",
      " [ 44 191]]\n",
      "tn= 466\n",
      "fp= 166\n",
      "fn= 44\n",
      "tp= 191\n",
      "------------------------\n",
      "PPV = 53.5\n",
      "(191/357)\n",
      "NPV = 91.4\n",
      "(466/510)\n",
      "sensitivity = 81.3\n",
      "(191/235)\n",
      "specificity = 73.7\n",
      "(466/632)\n"
     ]
    }
   ],
   "source": [
    "# Testing the model on the external validation set\n",
    "performance_xgboost(xtrainup,ytrainup,xv,yv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
